# ğŸ¤– AI Support Assistant - Complete Full-Stack Application

A modern, production-ready AI-powered customer support system with real-time screen sharing capabilities. Built with React, FastAPI, and pluggable AI architecture.

## ğŸŒŸ Features

### ğŸ¯ **Core Functionality**
- **Real-time AI Chat**: Intelligent conversations with context awareness
- **Smart Screen Sharing**: AI detects when visual guidance is needed
- **Dual-Panel Interface**: Chat + screen sharing in one seamless experience
- **Offline Mode**: Graceful fallback when backend is unavailable

### ğŸ¤– **Pluggable AI Architecture**
- **Multiple Providers**: OpenAI GPT, Anthropic Claude, easily extensible
- **Runtime Switching**: Change AI providers without restart
- **Smart Detection**: Analyzes user confusion to trigger screen sharing
- **Token Tracking**: Monitor usage and costs across providers

### ğŸ“º **Advanced Screen Sharing**
- **Agora Integration**: Professional-grade screen sharing
- **Secure Tokens**: Backend-generated authentication
- **Session Management**: Automatic cleanup and error handling
- **Browser Native**: Fallback to native screen capture

### ğŸš€ **Production Ready**
- **Responsive Design**: Mobile-first with desktop optimization
- **Error Handling**: Comprehensive error boundaries and fallbacks
- **Loading States**: Beautiful loading indicators and status updates
- **Health Monitoring**: Real-time connection status and provider info

## ğŸ“ Project Structure

```
ai-support/
â”œâ”€â”€ ğŸ¨ frontend/                 # React + Vite Frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/          # UI Components
â”‚   â”‚   â”‚   â”œâ”€â”€ ChatWindow.jsx   # Real-time chat interface
â”‚   â”‚   â”‚   â””â”€â”€ ScreenShare.jsx  # Screen sharing component
â”‚   â”‚   â”œâ”€â”€ services/            # API Layer
â”‚   â”‚   â”‚   â”œâ”€â”€ api.js           # Axios configuration
â”‚   â”‚   â”‚   â”œâ”€â”€ chatService.js   # Chat API integration
â”‚   â”‚   â”‚   â””â”€â”€ agoraService.js  # Agora token management
â”‚   â”‚   â”œâ”€â”€ pages/               # Page Components
â”‚   â”‚   â”‚   â””â”€â”€ Home.jsx         # Main application layout
â”‚   â”‚   â””â”€â”€ main.jsx             # Application entry point
â”‚   â”œâ”€â”€ package.json             # Dependencies and scripts
â”‚   â”œâ”€â”€ .env.example            # Environment template
â”‚   â””â”€â”€ README.md               # Frontend documentation
â”‚
â”œâ”€â”€ ğŸ”§ backend/                  # FastAPI Backend
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ agents/              # ğŸ¤– Pluggable AI Agents
â”‚   â”‚   â”‚   â”œâ”€â”€ base.py         # Abstract agent interface
â”‚   â”‚   â”‚   â”œâ”€â”€ openai_agent.py # OpenAI implementation
â”‚   â”‚   â”‚   â””â”€â”€ anthropic_agent.py # Anthropic implementation
â”‚   â”‚   â”œâ”€â”€ api/                 # RESTful API endpoints
â”‚   â”‚   â”œâ”€â”€ core/                # Configuration management
â”‚   â”‚   â”œâ”€â”€ models/              # Pydantic data models
â”‚   â”‚   â”œâ”€â”€ services/            # Business logic layer
â”‚   â”‚   â””â”€â”€ main.py             # FastAPI application
â”‚   â”œâ”€â”€ requirements.txt         # Python dependencies
â”‚   â”œâ”€â”€ .env.example            # Environment template
â”‚   â”œâ”€â”€ start.sh                # Startup script
â”‚   â””â”€â”€ README.md               # Backend documentation
â”‚
â””â”€â”€ ğŸ“– task.md                   # Project requirements
```

## ğŸš€ Quick Start

### Prerequisites
- **Node.js** 18+ and npm
- **Python** 3.11+ and pip
- **API Keys**: OpenAI and/or Anthropic (optional for demo)
- **Agora Account**: For production screen sharing (optional)

### 1. Clone & Setup
```bash
git clone <your-repo>
cd ai-support
```

### 2. Backend Setup
```bash
cd backend
python3 -m venv venv
source venv/bin/activate  # On Windows: venv\\Scripts\\activate
pip install -r requirements.txt
cp .env.example .env
# Edit .env with your API keys (optional for demo)
```

### 3. Frontend Setup
```bash
cd frontend
npm install
cp .env.example .env
# Default config works for local development
```

### 4. Start Development Servers

**Terminal 1 - Backend:**
```bash
cd backend
source venv/bin/activate
python -m uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

**Terminal 2 - Frontend:**
```bash
cd frontend
npm run dev
```

### 5. Access the Application
- **Frontend**: http://localhost:3000
- **Backend API**: http://localhost:8000
- **API Docs**: http://localhost:8000/docs

## ğŸ® How to Use

### 1. **Start Chatting**
- Open http://localhost:3000
- Type a message to the AI assistant
- Notice the connection status indicator

### 2. **Trigger Screen Sharing**
- Type messages with keywords like:
  - "I'm stuck"
  - "I have a problem"
  - "This isn't working"
  - "I need help"
- AI will request screen sharing

### 3. **Share Your Screen**
- Click "Share My Screen" when prompted
- Grant browser permissions
- See live preview while chatting continues

### 4. **Monitor System Status**
- Connection indicator shows online/offline status
- Current AI provider displayed in chat header
- Token usage shown for API calls
- Error messages with graceful fallbacks

## ğŸ”§ Configuration

### Frontend Environment (.env)
```env
# API Configuration
VITE_API_BASE_URL=http://localhost:8000

# Agora Configuration
VITE_AGORA_APP_ID=your_agora_app_id_here

# Development
VITE_DEBUG=true
```

### Backend Environment (.env)
```env
# AI API Keys (optional for demo)
OPENAI_API_KEY=your_openai_api_key_here
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# Agora Configuration (optional for demo)
AGORA_APP_ID=your_agora_app_id_here
AGORA_APP_CERTIFICATE=your_agora_app_certificate_here

# AI Configuration
DEFAULT_AI_PROVIDER=openai
AI_TEMPERATURE=0.7
AI_MAX_TOKENS=1000
```

## ğŸ¯ Key Features Demonstrated

### Smart AI Detection
The system analyzes user messages for:
- **Confusion Keywords**: "stuck", "error", "problem"
- **Emotional Indicators**: Frustration, urgency
- **Technical Patterns**: Error codes, technical issues
- **Question Density**: Multiple questions indicate uncertainty

### Pluggable Architecture
Switch AI providers easily:
```bash
# Via API
curl -X POST "http://localhost:8000/api/v1/agent/switch?provider=anthropic"

# Or through the UI (can be added)
```

### Error Handling
- **Network Issues**: Automatic fallback to offline mode
- **API Errors**: Graceful degradation with fallback responses
- **Token Limits**: Clear error messages and usage tracking
- **Screen Share Failures**: Detailed error messages and retry options

### Real-time Features
- **Connection Status**: Live monitoring of backend connectivity
- **Provider Info**: Current AI provider displayed
- **Token Usage**: Real-time API usage tracking
- **Session Management**: Automatic cleanup and error recovery

## ğŸ”„ API Integration Flow

### Chat Flow
1. **User types message** â†’ Frontend
2. **Message sent to backend** â†’ ChatService
3. **AI processes message** â†’ OpenAI/Anthropic Agent
4. **Confusion analysis** â†’ Smart detection algorithm
5. **Response returned** â†’ Frontend with screen share flag
6. **UI updates** â†’ Show response + screen share request

### Screen Share Flow
1. **AI requests screen sharing** â†’ Backend analysis
2. **Generate Agora token** â†’ Backend AgoraService
3. **User clicks "Share Screen"** â†’ Frontend
4. **Browser permission request** â†’ Native API
5. **Stream established** â†’ Live video feed
6. **Session info displayed** â†’ Channel name, token expiry

## ğŸ§ª Testing

### Test Chat API
```bash
curl -X POST "http://localhost:8000/api/v1/chat" \\
  -H "Content-Type: application/json" \\
  -d '{
    "message": "I need help with my computer",
    "user_id": "test_user"
  }'
```

### Test Provider Switching
```bash
curl -X POST "http://localhost:8000/api/v1/agent/switch?provider=anthropic"
```

### Test Health Check
```bash
curl -X GET "http://localhost:8000/api/v1/health"
```

## ğŸš€ Production Deployment

### Backend
```bash
# Using Docker
docker build -t ai-support-backend backend/
docker run -p 8000:8000 -e OPENAI_API_KEY=your_key ai-support-backend

# Or traditional deployment
gunicorn app.main:app -w 4 -k uvicorn.workers.UvicornWorker
```

### Frontend
```bash
npm run build
# Deploy dist/ folder to your static hosting service
```

### Environment Setup
- Set `DEBUG=false` for production
- Configure proper CORS origins
- Use secure secret keys
- Set up monitoring and logging

## ğŸ¨ Customization

### Adding New AI Providers
1. **Create agent class** implementing `AIAgent` interface
2. **Register in factory** (`app/agents/__init__.py`)
3. **Add configuration** in settings
4. **Update frontend** if needed

### UI Customization
- **Tailwind Classes**: Easy styling modifications
- **Component Props**: Flexible component configuration
- **Theme Variables**: Consistent color and spacing
- **Responsive Design**: Built-in mobile optimization

## ğŸ” Troubleshooting

### Common Issues

**Frontend shows "Offline Mode"**
- Check if backend is running on port 8000
- Verify CORS configuration in backend
- Check browser console for network errors

**AI responses are fallback messages**
- Verify API keys in backend .env file
- Check API key validity and quotas
- Monitor backend logs for detailed errors

**Screen sharing fails**
- Grant browser permissions for screen capture
- Check Agora configuration (optional for demo)
- Verify HTTPS in production (required for screen capture)

### Debug Mode
Enable detailed logging:
```env
# Frontend
VITE_DEBUG=true

# Backend  
DEBUG=true
```

## ğŸ¤ Contributing

1. **Fork the repository**
2. **Create feature branch** (`git checkout -b feature/amazing-feature`)
3. **Follow code standards** (ESLint, Black, etc.)
4. **Add tests** for new functionality
5. **Update documentation** as needed
6. **Submit pull request**

## ğŸ“ˆ Monitoring & Analytics

The system provides comprehensive metrics:
- **API Response Times**: Monitor backend performance
- **Token Usage**: Track AI API costs
- **Confusion Scores**: User satisfaction indicators
- **Error Rates**: System reliability metrics
- **Connection Status**: Real-time health monitoring

## ğŸ” Security

- **API Keys**: Never exposed in frontend
- **CORS**: Properly configured origins
- **Token Expiry**: Agora tokens automatically expire
- **Error Handling**: No sensitive data in error messages
- **Environment Variables**: Secure configuration management

---

## ğŸ‰ Success! Your AI Support Assistant is Live!

### What You've Built:
âœ… **Full-stack application** with React frontend and FastAPI backend  
âœ… **Pluggable AI architecture** supporting multiple providers  
âœ… **Real-time chat** with intelligent conversation management  
âœ… **Smart screen sharing** with automatic triggers  
âœ… **Production-ready features** with error handling and monitoring  
âœ… **Beautiful, responsive UI** with loading states and status indicators  

### Test It Out:
1. ğŸ’¬ **Chat with AI** - Try different message types
2. ğŸ–¥ï¸ **Trigger screen sharing** - Type "I'm stuck"
3. ğŸ”„ **See real-time updates** - Connection status, provider info
4. ğŸ› ï¸ **Handle errors gracefully** - Stop backend, see offline mode

Built with â¤ï¸ using React, FastAPI, OpenAI, Anthropic, and Agora for the ultimate AI support experience!# support
